{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract python codes from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base.py',\n",
       " 'completion.py',\n",
       " 'config.yaml',\n",
       " 'constants.py',\n",
       " 'main.py',\n",
       " 'moderation.py',\n",
       " 'utils.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_dir = '../../gpt-discord-bot/src/'\n",
    "file_list = os.listdir(file_dir); file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../gpt-discord-bot/src/base.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'from dataclasses import dataclass\\nfrom typing import Optional, List\\n\\nSEPARATOR_TOKEN = \"<|endoftext|>\"\\n\\n\\n@dataclass(frozen=True)\\nclass Message:\\n    user: str\\n    text: Optional[str] = None\\n\\n    def render(self):\\n        result = self.user + \":\"\\n        if self.text is not None:\\n            result += \" \" + self.text\\n        return result\\n\\n\\n@dataclass\\nclass Conversation:\\n    messages: List[Message]\\n\\n    def prepend(self, message: Message):\\n        self.messages.insert(0, message)\\n        return self\\n\\n    def render(self):\\n        return f\"\\\\n{SEPARATOR_TOKEN}\".join(\\n            [message.render() for message in self.messages]\\n        )\\n\\n\\n@dataclass(frozen=True)\\nclass Config:\\n    name: str\\n    instructions: str\\n    example_conversations: List[Conversation]\\n\\n\\n@dataclass(frozen=True)\\nclass Prompt:\\n    header: Message\\n    examples: List[Conversation]\\n    convo: Conversation\\n\\n    def render(self):\\n        return f\"\\\\n{SEPARATOR_TOKEN}\".join(\\n            [self.header.render()]\\n            + [Message(\"System\", \"Example conversations:\").render()]\\n            + [conversation.render() for conversation in self.examples]\\n            + [Message(\"System\", \"Current conversation:\").render()]\\n            + [self.convo.render()],\\n        )\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = os.path.join(file_dir, file_list[0]); fname\n",
    "f = open(fname, \"r\")\n",
    "code = f.read()\n",
    "code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add prompt to code to extract `class` and `def`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_postfix = \"\"\" \n",
    "###\n",
    "Here's what the above class is doing:\n",
    "1.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from dataclasses import dataclass\n",
      "from typing import Optional, List\n",
      "\n",
      "SEPARATOR_TOKEN = \"<|endoftext|>\"\n",
      "\n",
      "\n",
      "@dataclass(frozen=True)\n",
      "class Message:\n",
      "    user: str\n",
      "    text: Optional[str] = None\n",
      "\n",
      "    def render(self):\n",
      "        result = self.user + \":\"\n",
      "        if self.text is not None:\n",
      "            result += \" \" + self.text\n",
      "        return result\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Conversation:\n",
      "    messages: List[Message]\n",
      "\n",
      "    def prepend(self, message: Message):\n",
      "        self.messages.insert(0, message)\n",
      "        return self\n",
      "\n",
      "    def render(self):\n",
      "        return f\"\\n{SEPARATOR_TOKEN}\".join(\n",
      "            [message.render() for message in self.messages]\n",
      "        )\n",
      "\n",
      "\n",
      "@dataclass(frozen=True)\n",
      "class Config:\n",
      "    name: str\n",
      "    instructions: str\n",
      "    example_conversations: List[Conversation]\n",
      "\n",
      "\n",
      "@dataclass(frozen=True)\n",
      "class Prompt:\n",
      "    header: Message\n",
      "    examples: List[Conversation]\n",
      "    convo: Conversation\n",
      "\n",
      "    def render(self):\n",
      "        return f\"\\n{SEPARATOR_TOKEN}\".join(\n",
      "            [self.header.render()]\n",
      "            + [Message(\"System\", \"Example conversations:\").render()]\n",
      "            + [conversation.render() for conversation in self.examples]\n",
      "            + [Message(\"System\", \"Current conversation:\").render()]\n",
      "            + [self.convo.render()],\n",
      "        )\n",
      " \n",
      "###\n",
      "Here's what the above class is doing:\n",
      "1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = code +  prompt_postfix\n",
    "print(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request a response from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://tutorial-openai-01-2023.openai.azure.com/\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from utils import prompt_api, print_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "###\n",
      "Here's what the above class is doing:\n",
      "1.\n",
      "\n",
      "The Message class is a dataclass that is frozen, meaning that it cannot be changed. It has two attributes, user and text. The render method returns a string with the user and text. \n",
      "\n",
      "2.\n",
      "The Conversation class is a dataclass that is not frozen. It has one attribute, messages, which is a list of Message objects. The prepend method adds a message to the beginning of the list and the render method returns a string with all the messages separated by a separator token. \n",
      "\n",
      "3.\n",
      "The Config class is a dataclass that is frozen. It has three attributes, name, instructions, and example_conversations. \n",
      "\n",
      "4.\n",
      "The Prompt class is a dataclass that is frozen. It has four attributes, header, examples, and convo. The render method returns a string with the header, example conversations, and the current conversation.\n"
     ]
    }
   ],
   "source": [
    "engine=\"text-davinci-003\"  # note that text-davinci-x responds better than code-davinci-x\n",
    "prompt=prompt\n",
    "temperature=0 # [0, 1]\n",
    "max_tokens=300\n",
    "top_p=1\n",
    "frequency_penalty=0 # [0, 2]\n",
    "presence_penalty=0 # [0, 2]\n",
    "best_of=1\n",
    "stop=[\"###\"]\n",
    "\n",
    "response = prompt_api(engine, prompt, temperature, max_tokens, top_p, frequency_penalty, presence_penalty, best_of, stop)\n",
    "print(prompt_postfix)\n",
    "response_text = print_response(response); print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "###\n",
      "Here's what the above class is doing:\n",
      "1.\n",
      "The Message class is a dataclass that is frozen, meaning that it cannot be changed. It has two attributes, user and text. The render method returns a string with the user and text. \n",
      "\n",
      "2.\n",
      "The Conversation class is a dataclass that is not frozen. It has one attribute, messages, which is a list of Message objects. The prepend method adds a message to the beginning of the list and the render method returns a string with all the messages separated by a separator token. \n",
      "\n",
      "3.\n",
      "The Config class is a dataclass that is frozen. It has three attributes, name, instructions, and example_conversations. \n",
      "\n",
      "4.\n",
      "The Prompt class is a dataclass that is frozen. It has four attributes, header, examples, and convo. The render method returns a string with the header, example conversations, and the current conversation.\n"
     ]
    }
   ],
   "source": [
    "output = prompt_postfix + response_text\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output/explain_python_code/base.py.output'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file_dir = \"../output/explain_python_code/\"\n",
    "fname = os.path.join(output_file_dir, file_list[0] + '.output'); fname\n",
    "output_file = open(fname, \"w\")\n",
    "output_file.write(output)\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
